{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3eCevDEq5GdK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vl6DlQV5ROd",
        "outputId": "856083f9-92f0-46a0-a380-464bfd935549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data shape (20800, 4)\n",
            "                                                title              author  \\\n",
            "id                                                                          \n",
            "0   House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
            "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
            "2                   Why the Truth Might Get You Fired  Consortiumnews.com   \n",
            "3   15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
            "4   Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
            "\n",
            "                                                 text  label  \n",
            "id                                                            \n",
            "0   House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
            "1   Ever get the feeling your life circles the rou...      0  \n",
            "2   Why the Truth Might Get You Fired October 29, ...      1  \n",
            "3   Videos 15 Civilians Killed In Single US Airstr...      1  \n",
            "4   Print \\nAn Iranian woman has been sentenced to...      1  \n",
            "test data shape (5200, 4)\n",
            "      id                                              title  \\\n",
            "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
            "1  20801  Russian warships ready to strike terrorists ne...   \n",
            "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
            "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
            "4  20804                    Keiser Report: Meme Wars (E995)   \n",
            "\n",
            "                    author                                               text  \n",
            "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
            "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
            "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
            "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
            "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  \n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('/content/datasets/fake-news/train.csv')\n",
        "test = pd.read_csv('/content/datasets/fake-news/test.csv')\n",
        "train_data = train.copy()\n",
        "test_data = test.copy()\n",
        "\n",
        "train_data = train_data.set_index('id', drop = True)\n",
        "\n",
        "print('train data shape', train_data.shape)\n",
        "print(train_data.head())\n",
        "\n",
        "print('test data shape', test_data.shape)\n",
        "print(test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7YLALqD5gOB",
        "outputId": "9c8b4886-ffcb-4463-e9d9-3d31ab3d7e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values counts\n",
            " title      558\n",
            "author    1957\n",
            "text        39\n",
            "label        0\n",
            "dtype: int64\n",
            "missing values counts n title     0\n",
            "author    0\n",
            "text      0\n",
            "label     0\n",
            "dtype: int64\n",
            "train data length\n",
            "                                                 title              author  \\\n",
            "id                                                                          \n",
            "0   House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
            "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
            "2                   Why the Truth Might Get You Fired  Consortiumnews.com   \n",
            "3   15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
            "4   Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
            "\n",
            "                                                 text  label  length  \n",
            "id                                                                    \n",
            "0   House Dem Aide: We Didn’t Even See Comey’s Let...      1    4930  \n",
            "1   Ever get the feeling your life circles the rou...      0    4160  \n",
            "2   Why the Truth Might Get You Fired October 29, ...      1    7692  \n",
            "3   Videos 15 Civilians Killed In Single US Airstr...      1    3237  \n",
            "4   Print \\nAn Iranian woman has been sentenced to...      1     938  \n",
            "min data length 1 , max data length 142961 , average data length 4553\n",
            "count of less then 50 character 207\n",
            "min data length 50 , max data length 142961 , average data length 4598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-a8d1e3be196c>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_data['length'] = length\n"
          ]
        }
      ],
      "source": [
        "print('missing values counts\\n', train_data.isnull().sum())\n",
        "\n",
        "# dropping missing values from text columns alone.\n",
        "train_data[['title', 'author']] = train_data[['title', 'author']].fillna(value = 'Missing')\n",
        "train_data = train_data.dropna()\n",
        "print('missing values counts n', train_data.isnull().sum())\n",
        "\n",
        "length = []\n",
        "[length.append(len(str(text))) for text in train_data['text']]\n",
        "train_data['length'] = length\n",
        "print('train data length\\n', train_data.head())\n",
        "\n",
        "print('min data length', min(train_data['length']), ', max data length', max(train_data['length']), ', average data length', round(sum(train_data['length'])/len(train_data['length'])))\n",
        "\n",
        "print('count of less then 50 character', len(train_data[train_data['length'] < 50]))\n",
        "\n",
        "# dropping the outliers\n",
        "train_data = train_data.drop(train_data['text'][train_data['length'] < 50].index, axis = 0)\n",
        "print('min data length', min(train_data['length']), ', max data length', max(train_data['length']), ', average data length', round(sum(train_data['length'])/len(train_data['length'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkRCID7b5m4S",
        "outputId": "9c428011-dff2-4245-fec9-60dc2003309e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape (20554, 4500)\n",
            "Y shape (20554,)\n"
          ]
        }
      ],
      "source": [
        "max_features = 4500\n",
        "\n",
        "# Tokenizing the text - converting the words, letters into counts or numbers.\n",
        "# We dont need to explicitly remove the punctuations. we have an inbuilt option in Tokenizer for this purpose\n",
        "tokenizer = Tokenizer(num_words = max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower = True, split = ' ')\n",
        "tokenizer.fit_on_texts(texts = train_data['text'])\n",
        "X = tokenizer.texts_to_sequences(texts = train_data['text'])\n",
        "\n",
        "# now applying padding to make them even shaped.\n",
        "X = pad_sequences(sequences = X, maxlen = max_features, padding = 'pre')\n",
        "\n",
        "print('X shape', X.shape)\n",
        "y = train_data['label'].values\n",
        "print('Y shape', y.shape)\n",
        "\n",
        "# splitting the data training data for training and validation.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP987O9_5w92",
        "outputId": "70d5625f-675d-4a96-b119-4fb64a9f4387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 274 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7cb4f140b640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5149s\u001b[0m 10s/step - accuracy: 0.7763 - loss: 0.4585\n"
          ]
        }
      ],
      "source": [
        "# LSTM Neural Network\n",
        "lstm_model = Sequential(name = 'lstm_nn_model')\n",
        "lstm_model.add(layer = Embedding(input_dim = max_features, output_dim = 120, name = '1st_layer'))\n",
        "lstm_model.add(layer = LSTM(units = 120, dropout = 0.2, recurrent_dropout = 0.2, name = '2nd_layer'))\n",
        "lstm_model.add(layer = Dropout(rate = 0.5, name = '3rd_layer'))\n",
        "lstm_model.add(layer = Dense(units = 120,  activation = 'relu', name = '4th_layer'))\n",
        "lstm_model.add(layer = Dropout(rate = 0.5, name = '5th_layer'))\n",
        "lstm_model.add(layer = Dense(units = len(set(y)),  activation = 'sigmoid', name = 'output_layer'))\n",
        "# compiling the model\n",
        "lstm_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "lstm_model_fit = lstm_model.fit(X_train, y_train, epochs = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W1PqsgSV58F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0264250-58e5-4168-daf4-0fee3c282d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data shape (5200, 4)\n",
            "test_data shape (5200, 3)\n",
            "test_data shape (5200, 3)\n",
            "title     0\n",
            "author    0\n",
            "text      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 171 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cb4f0cd0e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 2s/step\n",
            "lstm_prediction [0 0 1 ... 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "test_data = test.copy()\n",
        "print('test_data shape', test_data.shape)\n",
        "\n",
        "test_data = test_data.set_index('id', drop = True)\n",
        "print('test_data shape', test_data.shape)\n",
        "\n",
        "test_data = test_data.fillna(' ')\n",
        "print('test_data shape', test_data.shape)\n",
        "print(test_data.isnull().sum())\n",
        "\n",
        "tokenizer.fit_on_texts(texts = test_data['text'])\n",
        "test_text = tokenizer.texts_to_sequences(texts = test_data['text'])\n",
        "\n",
        "test_text = pad_sequences(sequences = test_text, maxlen = max_features, padding = 'pre')\n",
        "\n",
        "lstm_prediction = lstm_model.predict(test_text)\n",
        "\n",
        "lstm_prediction_vec = np.argmax(lstm_prediction, axis=1)\n",
        "\n",
        "print(\"lstm_prediction\", lstm_prediction_vec)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}